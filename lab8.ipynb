{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8\n",
    "## Data Structures & Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today\n",
    "* [Divide-and-conquer refresher](#divide)\n",
    "* [Bubble Sort](#motivation-bubble-sort)\n",
    "* [Improved Bubble Sort](#improved-bubble-sort)\n",
    "* [Merge Sort](#merge-sort)\n",
    "* [A Recurrence Relation](#a-recurrency-relation)\n",
    "* [Master Theorem](#master-theorem)\n",
    "* [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide-and-conquer refresher\n",
    "\n",
    "Divide-and-conquer algorithms are a class of algorithms that solve a problem by:\n",
    "1. **Divide**: Breaking the problem into smaller, more manageable subproblems.\n",
    "2. **Conquer**: Solving the subproblems recursively.\n",
    "3. **Combine**: Merging the solutions of the subproblems to solve the original problem.\n",
    "\n",
    "### Examples\n",
    "\n",
    "You saw examples for divide-and-conquer algorithms in the lecture, here is a subselection of those:\n",
    "\n",
    "- **Merge Sort**: A sorting algorithm that \n",
    "    1. divides the array into two halves, \n",
    "    2. sorts each half recursively, \n",
    "    3. and then merges the sorted halves.\n",
    "- **Quick Sort**: Another sorting algorithm that: \n",
    "    1. selects a pivot element, \n",
    "    2. partitions the array around the pivot, \n",
    "    3. and then sorts the subarrays recursively.\n",
    "- **Binary Search**: A searching algorithm that:\n",
    "    1. divides the sorted array in half at each step,\n",
    "    2. at each step searches to find the target element, \n",
    "    3. does so recursively.\n",
    "- **Strassen's Algorithm**: A matrix multiplication algorithm that: \n",
    "    1. divides matrices into smaller submatrices, \n",
    "    2. recursively, \n",
    "    3. and combines their products efficiently.\n",
    "- **Karatsuba Multiplication**: A multiplication algorithm for two $n$-digit numbers which reduces the process to three multiplications of $\\frac{n}{2}$-digit numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation: Bubble Sort\n",
    "\n",
    "Before we dive into advanced sorting techniques like divide-and-conquer algorithms (e.g., Merge Sort or Quick Sort), it's useful to first understand a simpler, more intuitive sorting method: Bubble Sort.\n",
    "\n",
    "**Idea of Bubble Sort**: \n",
    "\n",
    "*Bubble Sort is a straightforward (i.e. brute force) sorting algorithm that works by repeatedly swapping adjacent elements if they are in the wrong order. The idea is to \"bubble up\" the largest element to its correct position in each pass.*\n",
    "1. **Repeated passes**: We iterate through the array $n$ times (where $n$ is the length of the array). \n",
    "2. **Pairwise Swapping**: \n",
    "    - Compare each adjacent pair of elements.\n",
    "    - If the first element is greater than the second, swap them.\n",
    "\n",
    "Effect of Swapping:\n",
    "- After the first full pass, the largest element moves to the last position.\n",
    "- After the second full pass, the second largest element is in its correct position, and so on.\n",
    "- This continues until the array is fully sorted.\n",
    "\n",
    "Here's an example implementation of bubble sort in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort_brute_force(arr):\n",
    "    \"\"\"\n",
    "    Bubble sort \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : a list of number\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    The list sorted in ascending order\n",
    "    \"\"\"\n",
    "    \n",
    "    arr_temp = list(arr)\n",
    "    n = len(arr_temp)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n - 1):\n",
    "            # Get the difference between two adjacent numbers\n",
    "            diff = arr_temp[j] - arr_temp[j + 1]\n",
    "            if diff > 0:\n",
    "                # Swap the two numbers\n",
    "                arr_temp[j], arr_temp[j + 1] = arr_temp[j + 1], arr_temp[j]               \n",
    "\n",
    "    return arr_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[3]\n",
      "[2, 3]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "arr_1 = []\n",
    "arr_2 = [3]\n",
    "arr_3 = [3, 2]\n",
    "arr_4 = [3, 2, 1, 4]\n",
    "\n",
    "print(bubble_sort_brute_force(arr_1))\n",
    "print(bubble_sort_brute_force(arr_2))\n",
    "print(bubble_sort_brute_force(arr_3))\n",
    "print(bubble_sort_brute_force(arr_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complexity\n",
    "\n",
    "The time complexity of bubble sort is $O(n^2)$. \n",
    "- In the worst-case scenario, where the input array is in reverse order, bubble sort will need to make $n$ passes through the array, with each pass requiring $O(n)$ comparisons and swaps. \n",
    "- So, despite its simplicity, bubble sort is not efficient for sorting large arrays due to its quadratic time complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Bubble Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save on some operations: \n",
    "- We know that in the first round, the largest number will be moved to the last place of the array. \n",
    "- So, in the second round, we do not have to consider the last element in the array as it is the largest element that we moved there in the first round. \n",
    "- By extension, in the third round, we can ignore the last two elements.\n",
    "- ...and so on. \n",
    "- To formalise this: in round $i$, we can ignore the last $i-1$ elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort_improved(arr):\n",
    "    \"\"\"\n",
    "    Bubble sort \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : a list of number\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    The list sorted in ascending order\n",
    "    \"\"\"\n",
    "    \n",
    "    arr_temp = list(arr)\n",
    "    n = len(arr_temp)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # in the second loop, we are leaving out the last i-1 elements of the array\n",
    "        for j in range(n - i - 1):\n",
    "            # Get the difference between two adjacent numbers\n",
    "            diff = arr_temp[j] - arr_temp[j + 1]\n",
    "            if diff > 0:\n",
    "                # Swap the two numbers\n",
    "                arr_temp[j], arr_temp[j + 1] = arr_temp[j + 1], arr_temp[j]               \n",
    "\n",
    "    return arr_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complexity\n",
    "\n",
    "NB: this still has running time $O(n^2)$, but it will still be a bit faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Sort\n",
    "\n",
    "Merge sort is another sorting algorithm that follows the divide-and-conquer approach. It works by:\n",
    "1. Dividing the array into two halves, \n",
    "2. Sorting each half recursively, \n",
    "3. Merging the sorted halves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "   <img src=\"images/mergesort_viz.png\" width=\"500px\" title=\"mergesort visualisation\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example implementation of merge sort in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(arr):\n",
    "    \"\"\"\n",
    "    Merge sort \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : a list of number\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    The list sorted in ascending order\n",
    "    \"\"\"\n",
    "    arr_temp = list(arr)\n",
    "    n = len(arr_temp)    \n",
    "    \n",
    "    if n > 1: \n",
    "        # STEP 1: DIVIDE\n",
    "        # Divide the list into two smaller ones\n",
    "        # The middle of the list\n",
    "        mid = n // 2 # using floor division (a.k.a integer division)\n",
    "        # The left sublist\n",
    "        arr_temp_left = arr_temp[:mid] \n",
    "        # The right sublist\n",
    "        arr_temp_right = arr_temp[mid:]\n",
    "\n",
    "        # STEP 2: RECURSIVE CALL (UNTIL N=1)\n",
    "        # Recursively call merge_sort to sort the two smaller lists\n",
    "        arr_temp_left = merge_sort(arr_temp_left)\n",
    "        arr_temp_right = merge_sort(arr_temp_right)\n",
    "        \n",
    "        # STEP 3: MERGE  \n",
    "        # Merge the two sorted smaller lists\n",
    "        i = j = k = 0\n",
    "        n_left, n_right = len(arr_temp_left), len(arr_temp_right)\n",
    "          \n",
    "        while i < n_left and j < n_right: \n",
    "            if arr_temp_left[i] < arr_temp_right[j]: \n",
    "                arr_temp[k] = arr_temp_left[i] \n",
    "                i += 1\n",
    "            else: \n",
    "                arr_temp[k] = arr_temp_right[j] \n",
    "                j += 1\n",
    "            k += 1\n",
    "          \n",
    "        # If there are elements in arr_temp_left that have not been visited \n",
    "        while i < n_left: \n",
    "            arr_temp[k] = arr_temp_left[i] \n",
    "            i += 1\n",
    "            k += 1\n",
    " \n",
    "        # If there are elements in arr_temp_right that have not been visited \n",
    "        while j < n_right: \n",
    "            arr_temp[k] = arr_temp_right[j] \n",
    "            j += 1\n",
    "            k += 1\n",
    "            \n",
    "    return arr_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[3]\n",
      "[2, 3]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "arr_1 = []\n",
    "arr_2 = [3]\n",
    "arr_3 = [3, 2]\n",
    "arr_4 = [3, 2, 1, 4]\n",
    "\n",
    "print(merge_sort(arr_1))\n",
    "print(merge_sort(arr_2))\n",
    "print(merge_sort(arr_3))\n",
    "print(merge_sort(arr_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Complexity Analysis\n",
    "\n",
    "Merge Sort has a time complexity of $O(n \\log n)$ in all cases, making it a more efficient sorting algorithm than Bubble Sort. \n",
    "\n",
    "It achieves this time complexity by dividing the array into halves recursively and merging the sorted halves *efficiently*.\n",
    "\n",
    "Let's look at this in more detail: remember that for divide-and-conquer algorithms, we use a **recurrence relation** to express the running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Recurrence Relation\n",
    "First, let's say $T(n)$ is the worst-case running time of the algorithm for an input of size $n$.\n",
    "\n",
    "For MergeSort: $T(n)$ can be decomposed into 3 separate processes at each step:\n",
    "      1. we subdivide the problem (in this case into two pieces of size $n/2$). \n",
    "      2. we then know that the algorithm will spend $T(n/2)$ on each sub-problem \n",
    "      3. plus some amount of time (in this case $O(n)$) on combining the subproblems. \n",
    "\n",
    "The running time of MergeSort algorithm therefore satisfies the following recurrence relation:\n",
    "\n",
    "<div>\n",
    "   <img src=\"images/screenshot_mergesort.png\" width=\"300px\">\n",
    "</div>\n",
    "\n",
    "There are different ways of solving such a recurrence relation (i.e. make $T$ only appear on the left-hand side of the inequality). The most intuitive way is to 'unroll' the recurrence and look at patterns in the first few levels:\n",
    "\n",
    "<div>\n",
    "   <img src=\"images/screenshot_rectree_mergesort.png\" width=\"500px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's going on here? \n",
    "\n",
    "*For all levels, the division operation is $c$ -- $O(1)$ -- so we can effectively ignore it and focus on the merge and recurion elements!*\n",
    "\n",
    "1. **Top Level (Entire Array of Size $n$)**\n",
    "   - The merge operation (combining sorted halves) takes $O(n)$ time *(we just assert this for now)*.\n",
    "   - We also make two recursive calls to sort the left and right halves.\n",
    "2. **Second Level (Two Subproblems of Size $n/2$)**\n",
    "   - Each of the two halves is of size $n/2$.\n",
    "   - Each half takes at most $O(n/2)$ time for merging.\n",
    "   - Since there are two such halves, the total time at this level is still $O(n)$.\n",
    "3. **Third Level (Four Subproblems of Size $n/4$)**\n",
    "   - Each subproblem is now $n/4$ in size.\n",
    "   - Each takes at most $O(n/4)$ time for merging.\n",
    "   - Since there are four such subproblems, the total time at this level remains $O(n)$.\n",
    "- **Generalizing to Deeper Levels**\n",
    "   - At each level of recursion, the total merging time remains $O(n)$ because there are always enough subproblems to sum up to $n$.\n",
    "   - The recursion continues until we reach base cases (single-element arrays).\n",
    "\n",
    "#### So at level $j$: \n",
    "1. Number of Subproblems at Level $j$\n",
    "   - At each level of recursion, the number of subproblems **doubles** compared to the previous level.\n",
    "   - We start with **1 subproblem** (the entire array), after $j$ levels, there are: $2^j \\text{ subproblems}$\n",
    "\n",
    "2. Size of Each Subproblem at Level $j$\n",
    "   - The array is divided in half at every level.\n",
    "   - After $j$ levels, each subproblem is of size: $\\frac{n}{2^j}$:\n",
    "      - after **one split**, the size is $ n/2 $, \n",
    "      - after **two splits**, it's $ n/4 $, \n",
    "      - and so on.\n",
    "\n",
    "3. Total Work Done at Level $j$\n",
    "   - As before, the division operation is done in constant time, so it drops out. This leaves us just with merging and recursion.\n",
    "   - Each of the $ 2^j $ subproblems requires at most $ O(n/2^j) $ time for merging.\n",
    "   - Since there are $ 2^j $ such subproblems, the total work done at level $j$ is: $2^j \\cdot \\frac{n}{2^j} = n$\n",
    "\n",
    "**The key point to get here is that the total work remains $ O(n) $ at **every** level!**\n",
    "\n",
    "4. Summing Over All Levels\n",
    "   - The recursion continues until we reach base cases where the subproblem size is **1**.\n",
    "   - The number of levels required to reduce $ n $ down to **1** is the number of times we can halve $ n $:\n",
    "   \n",
    "   $$\\log_2 n$$\n",
    "   \n",
    "   - Since we do **$ O(n) $ work at each level**, and there are $ O(\\log n) $ levels, the total time complexity is:\n",
    "   $$O(n \\log n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Theorem\n",
    "\n",
    "Another way to solve recurrence relations is to use the **Master Theorem**.\n",
    "\n",
    "The Master Theorem provides a systematic way to analyze the runtime of divide-and-conquer algorithms by expressing their recurrence relation in a general form:\n",
    "\n",
    "$$\n",
    "T(n) = aT\\left(\\frac{n}{b}\\right) + O(n^c)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ a $ is the number of recursive subproblems created at each step.\n",
    "- $ b $ is the factor by which the problem size shrinks at each level.\n",
    "- $ c $ is the cost of the merging or combining step.\n",
    "\n",
    "This gives the following properties:\n",
    "- $1 + \\log_b n$ is the number of levels (the **depth**),\n",
    "- $\\frac{n}{b^i}$ is the **size** of subproblems at level $i$,\n",
    "- $a^i$ is the **number** of subproblems at level $i$.\n",
    "\n",
    "### General Form of Running Time\n",
    "Using these properties we can work out a general form of running time for any divide-and-conquer problem.\n",
    "\n",
    "Following a pattern similar to the **recursion tree analysis**, we sum the work done **at each level** of recursion: given by the relationship between \n",
    "  1. the depth of the recursion, \n",
    "  2. the scaling of the subproblems at each level, \n",
    "  2. and the number of subproblems produced at each level.\n",
    "\n",
    "Formally:\n",
    "- The recursion **depth** is $ \\log_b n $ (since the problem size reduces by a factor of $ b $ at each level).\n",
    "  - where $n$ is the length of the\n",
    "- At each level, the work done depends on:\n",
    "  1. **The number of subproblems** at that level. ($a^i$)\n",
    "  2. **The size of each subproblem** and the time required to process it. ($\\frac{n}{b^i}$)\n",
    "\n",
    "These factors determine the recurrence ratio $ r $, which helps classify the running time into one of three cases.\n",
    "\n",
    "### Classifying Time Complexity with the Master Theorem\n",
    "Formally, we can define the following:\n",
    "\n",
    "$$\n",
    "r = \\frac{a}{b^c}\n",
    "$$\n",
    "\n",
    "The total running time follows:\n",
    "\n",
    "$$\n",
    "T(n) = n^c \\sum_{i=0}^{\\log_b n} r^i\n",
    "$$\n",
    "\n",
    "which leads to the following cases:\n",
    "\n",
    "$$\n",
    "T(n) =\n",
    "\\begin{cases} \n",
    "O(n^c) & \\text{if } r < 1 \\quad (c > \\log_b a) \\quad \\text{(Root-dominated)} \\\\\n",
    "O(n^c \\log n) & \\text{if } r = 1 \\quad (c = \\log_b a) \\quad \\text{(Balanced)} \\\\\n",
    "O(n^{\\log_b a}) & \\text{if } r > 1 \\quad (c < \\log_b a) \\quad \\text{(Leaf-dominated)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### Root-Dominated, Balanced, and Leaf-Dominated Cases\n",
    "The Master Theorem helps determine whether an algorithm's time complexity is:\n",
    "- **Root-dominated**: Work is mainly done at the top level (combining step).\n",
    "- **Balanced**: Work is evenly distributed across levels.\n",
    "- **Leaf-dominated**: Work is mainly done at the leaves (smallest subproblems).\n",
    "\n",
    "## Example Analysis\n",
    "Consider an algorithm where:\n",
    "1. The **combining step** takes linear time ($ c = 1 $).\n",
    "2. The problem is divided into **subproblems** of size $ n/2 $ (i.e., $ b = 2 $).\n",
    "\n",
    "Thus, we compute:\n",
    "\n",
    "$$\n",
    "r = \\frac{a}{2}\n",
    "$$\n",
    "\n",
    "For different values of $ a $, we get different running times:\n",
    "\n",
    "| **Number of Subproblems ($ a $)** | **Running Time** | **Classification** |\n",
    "|--------------|----------------|------------------|\n",
    "| $ a = 1 $ | $ O(n) $ | **Root-dominated** (Cost dominated by the top level) |\n",
    "| $ a = 2 $ | $ O(n \\log n) $ | **Balanced** (Merge Sort case) |\n",
    "| $ a > 2 $ | $ O(n^{\\log_2 a}) $ | **Leaf-dominated** (Cost dominated by the leaves) |\n",
    "\n",
    "*NB: in our MergeSort case, $a=2$ and $b^c=2$, so it is linear; it produces two subproblems at each level, but each subproblem's size is halved.*\n",
    "\n",
    "### Intuition Behind These Cases\n",
    "- **When $ a = 1 $:** \n",
    "  - Each recursive call reduces the problem size, but since there's only one subproblem at each step, the total work remains **linear**.\n",
    "  - The **top-level work (combining step)** dominates the complexity.\n",
    "  <div>\n",
    "   <img src=\"images/screenshot_rectree_a1.png\" width=\"200px\">\n",
    "  </div>  \n",
    "  \n",
    "- **When $ a = 2 $ (Merge Sort case):** \n",
    "  - Each level does roughly the same amount of work.\n",
    "  - The recursion **depth is $ \\log n $**, and each level takes $ O(n) $, so the total time is $ O(n \\log n) $.\n",
    "  - Work is **evenly distributed across levels**.\n",
    "  <div>\n",
    "   <img src=\"images/mergesort_viz.png\" width=\"500px\" title=\"mergesort visualisation\">\n",
    "  </div>\n",
    "\n",
    "- **When $ a > 2 $:**\n",
    "  - The number of subproblems grows **faster than the problem size shrinks**, leading to an increasing workload at the lower levels.\n",
    "  - The **leaves of the recursion tree** dominate the total complexity.\n",
    "  <div>\n",
    "   <img src=\"images/screenshot_rectree_a3.png\" width=\"500px\">\n",
    "  </div>\n",
    "\n",
    "(All visualisations of recursive trees are taken from the Kleinberg textbook, which also has great further explanations in it!).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Extend the bubble sort algorithm from above, to make it even more efficient. \n",
    "\n",
    "When we pass an already sorted array to the implementation of the algorithm above, it always goes through the array $n$ times, which is unnecessary. In this even further improved version, we want to make sure that after each round of passing through the array, we first check if the array has already been sorted and we terminate the algorithm as soon as we find that it has. Implement this according to the following idea:\n",
    "\n",
    "* remember that we compare each two adjacent elements in the array and do a swap if the first is larger than the second\n",
    "* this means that if no two elements were swapped in a round, the array is already sorted!\n",
    "* include a variable in your code that indicates if any swap was made in a round\n",
    "* then terminate the algorithm once the flag variable has not recorded any swaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort_optimal(arr):\n",
    "    \"\"\"\n",
    "    Bubble sort \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : a list of number\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    The list sorted in ascending order\n",
    "    \"\"\"\n",
    "\n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Modify the merge sort algorithm to sort the elements in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort_desc(arr):\n",
    "    \"\"\"\n",
    "    Merge sort in descending order\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : list\n",
    "        A list of numbers\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The list sorted in descending order\n",
    "    \"\"\"\n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "As discussed in the lecture, an **inversion** in an array is when for two elements `array[i]` and `array[j]` we have `array[i]` > `array[j]` and `i < j`. E.g. `array = [3,1,2]` has two inversion: `(3,1)` and `(3,2)`. In other words, an inversion is every pair of elements that is violating an ascending order of the elements.\n",
    "\n",
    "Implement an algorithm for counting inversions in a naive way, where you go through every single pair of elements and check if it is an inversion. If it is, increase a counter by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_inversions_brute_force(arr):\n",
    "    \"\"\"\n",
    "    Count inversions in an array using the brute-force approach.\n",
    "    \n",
    "    Inversion in an array occurs when a pair of elements (arr[i], arr[j]) where i < j,\n",
    "    and arr[i] > arr[j].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : list\n",
    "        A list of numbers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The number of inversions in the array.\n",
    "    \"\"\"\n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "What is the time and space complexity of this algorithm? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Now, implement the counting inversions algorithm so that it runs in $O(n \\log n)$ using divide-and-conquer. In the end, it should return the total number of inversions and the sorted input array. Remember what you learnt about this in the lectures and read the very helpful section in the Algorithm Design (Kleinberg & Tardos) textbook (in chapter 5). The following hints for the implementations (and the solutions that will be provided) come from [this](https://www.geeksforgeeks.org/python-program-for-count-inversions-in-an-array-set-1-using-merge-sort/) website. Do try this yourself before looking at the implementation!\n",
    "\n",
    "* the idea of divide-and-conquer is always to recursively divide the array into subarrays\n",
    "* imagine that we divide an array into two subarrays and manage to find the number of inversions for each\n",
    "* to find the total number of inversions, we are then only missing the inversions that need to be counted across the two subarray (i.e. in the 'combination' or 'merge' step of the divide-and-conquer algorithm)\n",
    "* so the total number of inversions is the number of inversions in the left subarray, right subarray, and merge().\n",
    "* to get the number of inversions in merge(): let i is used for indexing left sub-array and j for right sub-array. At any step in merge(), if a[i] is greater than a[j], then there are (mid – i) inversions. because left and right subarrays are sorted, so all the remaining elements in left-subarray (a[i+1], a[i+2] … a[mid]) will be greater than a[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with the last part of the algorithm (counting the inversions in 'merge'), first write a merge-and-sort functions according to the following pseudo code from the Algorithm Design textbook. Note that this is a **very** similar algorithm to a part of the merge sort algorithm we looked at above (except you also have to keep track of the inversions as you merge the two arrays).\n",
    "\n",
    "```\n",
    "Merge-and-Count(A,B)\n",
    "    Maintain a Current pointer into each list, initialized to point to the front elements (e.g. use i and j, that are both 0 to start with)\n",
    "    Maintain a variable Count for the number of inversions, initialized to 0\n",
    "    While both lists are nonempty:\n",
    "        Let ai and bj be the elements pointed to by the Current pointers, ai = A[i] and bj = B[j]\n",
    "        Append the smaller of these two to the output list\n",
    "        If bj is the smaller element:\n",
    "            Increment Count by the number of elements remaining in A\n",
    "        Endif\n",
    "        Advance the Current pointer in the list from which the smaller element was selected.\n",
    "    EndWhile\n",
    "    Once one list is empty, append the remainder of the other list to the output\n",
    "    Return Count and the merged list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_count(A, B):\n",
    "    \"\"\"\n",
    "    Merge two sorted lists and count inversions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : list\n",
    "        A sorted list.\n",
    "    B : list\n",
    "        Another sorted list.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple\n",
    "        A tuple containing the merged sorted list and the number of inversions.\n",
    "    \"\"\"\n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "We now use the function written in the last exercise, to write the algorithm for counting inversions, that we call `sort_and_count`.\n",
    "\n",
    "Again, use the pseudo-code from the text book as a helper:\n",
    "\n",
    "```\n",
    "Sort-and-Count(L)\n",
    "If the list has one element:\n",
    "    there are no inversions\n",
    "Else\n",
    "    Divide the list into two halves:\n",
    "        A contains the first ⌈n/2⌉ elements\n",
    "        B contains the remaining ⌊n/2⌋ elements\n",
    "    (rA, A) = Sort-and-Count(A)\n",
    "    (rB, B) = Sort-and-Count(B)\n",
    "    (r,L) = Merge-and-Count(A,B)\n",
    "Endif\n",
    "Return r =rA +rB +r, and the sorted list L\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_count(L):\n",
    "    \"\"\"\n",
    "    Sort a list and count inversions using divide-and-conquer approach\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    L : list\n",
    "        A list of elements.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple\n",
    "        A tuple containing the number of inversions and the sorted list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "Use the Master Theorem to give time complexity of the algorithm in Exercise 6 and say whether it is root-dominated, leaf-dominated or balanced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
